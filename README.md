**Overview**

This repository demonstrates two essential techniques in data mining: Data Cleaning and Normalization. Both techniques are crucial preprocessing steps for ensuring the quality and consistency of datasets, enabling accurate analysis and reliable machine learning models.

**Data Cleaning:** Involves identifying and handling errors, missing values, and inconsistencies in data to ensure its quality.

**Normalization:** The process of transforming data into a standard scale to improve model performance and ensure that all features contribute equally to the analysis.
This project includes scripts and examples for applying these techniques to raw datasets.

**Key Features**

**Data Cleaning Techniques:**

- Handling missing values (imputation, removal).
- Detecting and removing duplicates.
- Resolving inconsistent formatting and correcting erroneous entries.

**Normalization Techniques:**

- Min-Max scaling.
- Z-score normalization (standardization).
- Robust scaling for handling outliers.

**Reusable Scripts:**

- Python scripts for automating cleaning and normalization tasks on any dataset.

**Example Datasets:**

- Real-world datasets for demonstrating the cleaning and normalization process.
